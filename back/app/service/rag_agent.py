import os
import json
import time
import uuid
import logging
import subprocess
from functools import wraps
from pathlib import Path
from dotenv import load_dotenv
import tomllib
from langchain_google_genai import ChatGoogleGenerativeAI
from langchain.prompts import PromptTemplate
from langchain.schema.runnable import RunnableSequence
from langchain_core.output_parsers import StrOutputParser


from app.tools.lint import format_and_linter
from app.tools.manim_lint import parse_manim_or_python_traceback, format_error_for_llm
from app.tools.secure import is_code_safe
from app.tools.embeding_data.manim_rag import ManimDocsRAG


# =========================
# ãƒ­ã‚®ãƒ³ã‚°å…±é€šãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£
# =========================
LOG_LEVEL = os.getenv("LOG_LEVEL", "INFO").upper()
TRACE_LLM = bool(int(os.getenv("TRACE_LLM_PROMPTS", "0")))
TRIM = int(os.getenv("LOG_TRIM", "1200"))  # é•·æ–‡ã‚’ãƒ­ã‚°å‡ºåŠ›ã™ã‚‹ã¨ãã®æœ€å¤§æ–‡å­—æ•°

def _setup_logger() -> logging.Logger:
    logger = logging.getLogger("manim_rag_service")
    if logger.handlers:
        return logger
    logger.setLevel(getattr(logging, LOG_LEVEL, logging.INFO))
    handler = logging.StreamHandler()
    fmt = "%(asctime)s.%(msecs)03d %(levelname)s [%(name)s] %(message)s"
    handler.setFormatter(logging.Formatter(fmt=fmt, datefmt="%Y-%m-%d %H:%M:%S"))
    logger.addHandler(handler)
    logger.propagate = False
    return logger

logger = _setup_logger()

def _redact(s: str) -> str:
    if not isinstance(s, str):
        return s
    s = s.replace(os.getenv("GEMINI_API_KEY", "*****") or "*****", "****REDACTED****")
    return s

def _clip(s: str, n: int = TRIM) -> str:
    if not isinstance(s, str):
        return s
    return s if len(s) <= n else s[: n] + f"... <trimmed {len(s)-n} chars>"

def trace(func):
    """é–¢æ•°ã®å…¥å‡ºãƒ»æ‰€è¦æ™‚é–“ã‚’çµ±ä¸€ãƒ­ã‚°ã€‚é•·æ–‡ã¯è‡ªå‹•ãƒˆãƒªãƒ ã€‚"""
    @wraps(func)
    def wrapper(*args, **kwargs):
        call_id = str(uuid.uuid4())[:8]
        t0 = time.perf_counter()
        try:
            safe_kwargs = {
                k: _clip(_redact(v)) if isinstance(v, str) else v
                for k, v in kwargs.items()
            }
            logger.debug(f"â–¶ï¸  {func.__name__} start call_id={call_id} kwargs={safe_kwargs}")
            out = func(*args, **kwargs)
            t1 = time.perf_counter()
            logger.debug(f"âœ…  {func.__name__} end   call_id={call_id} elapsed={t1-t0:.3f}s "
                         f"result_preview={_clip(str(out))}")
            return out
        except Exception as e:
            t1 = time.perf_counter()
            logger.exception(f"ğŸ’¥ {func.__name__} error call_id={call_id} elapsed={t1-t0:.3f}s: {e}")
            raise
    return wrapper

load_dotenv()

class ManimAnimationOnRAGService:
    def __init__(self):
        self.req_id = str(uuid.uuid4())[:8]
        base_dir = Path(__file__).resolve().parent
        prompts_path = base_dir / "prompts.toml"
        prompts_path = str(prompts_path)
        logger.info(f"[{self.req_id}] åˆå§‹åŒ– start prompts_path={prompts_path}")
        with open(prompts_path, 'rb') as f:
            self.prompts = tomllib.load(f)

        # LLMèª­ã¿è¾¼ã¿
        self.think_llm = self._load_llm("gemini-2.5-flash")
        self.pro_llm   = self._load_llm("gemini-2.5-pro")
        self.flash_llm = self._load_llm("gemini-2.5-flash")
        self.lite_llm  = self._load_llm("gemini-2.5-flash-lite")
        self.rag_client = ManimDocsRAG(logger=logger)

        # optional_variables ã¯ LangChain ã® PromptTemplate ã«ã¯ç„¡ã„ã‚ªãƒ—ã‚·ãƒ§ãƒ³
        # â†’ å°†æ¥ã®æ··ä¹±ã‚’é¿ã‘ã‚‹ãŸã‚è­¦å‘Šã®ã¿å‡ºã—ã€æ©Ÿèƒ½ã¯ãã®ã¾ã¾ï¼ˆç„¡è¦–ã•ã‚Œã‚‹ï¼‰
        if logger.isEnabledFor(logging.WARNING):
            logger.warning(f"[{self.req_id}] æ³¨æ„: PromptTemplate ã« 'optional_variables' ã¯å­˜åœ¨ã—ã¾ã›ã‚“ï¼ˆç„¡è¦–ã•ã‚Œã¾ã™ï¼‰")

        logger.info(f"[{self.req_id}] åˆå§‹åŒ– done")

    def _load_llm(self, model_type: str):
        logger.debug(f"[{self.req_id}] LLMãƒ­ãƒ¼ãƒ‰ model={model_type}")
        return ChatGoogleGenerativeAI(model=model_type, google_api_key=os.getenv('GEMINI_API_KEY'))

    # çŸ¥è­˜ã®æ§‹é€ åŒ–èª¬æ˜
    @trace
    def explain_concept(self, input_text: str) -> str:
        if TRACE_LLM:
            logger.debug(f"[{self.req_id}] explain_concept.prompt =\n{_clip(self.prompts['explain']['prompt'])}")
            logger.debug(f"[{self.req_id}] explain_concept.vars = {{'input_text': '{_clip(input_text)}'}}")

        prompt = PromptTemplate(
            input_variables=["input_text"],
            template=self.prompts["explain"]["prompt"]
        )
        parser = StrOutputParser()
        chain = RunnableSequence(
            first=prompt | self.flash_llm,
            last=parser
        )
        output = chain.invoke({"input_text": input_text})
        if TRACE_LLM:
            logger.debug(f"[{self.req_id}] explain_concept.output =\n{_clip(output)}")
        return output

    # ã‚¹ã‚¯ãƒªãƒ—ãƒˆã‚’ä½œæˆã™ã‚‹æœ€æ–°prompt
    @trace
    def generate_script_with_prompt(self, explain_prompt, video_enhance_prompt):
        """
        å‹•ç”»ã®ã‚¹ã‚¯ãƒªãƒ—ãƒˆã‚’ç”Ÿæˆã™ã‚‹é–¢æ•°
        """
        if TRACE_LLM:
            logger.debug(f"[{self.req_id}] generate_script_with_prompt.planner_template =\n"
                         f"{_clip(self.prompts['chain']['manim_planer_with_instruct'])}")
            logger.debug(f"[{self.req_id}] generate_script_with_prompt.script_template =\n"
                         f"{_clip(self.prompts['chain']['manim_script_generate'])}")

        # NOTE: optional_variables ã¯ç„¡è¦–ã•ã‚Œã‚‹
        manim_planer = PromptTemplate(
            input_variables=['user_prompt', 'video_enhance_prompt'],
            template=self.prompts['chain']['manim_planer_with_instruct']
        )
        parser = StrOutputParser()

        manim_script_prompt = PromptTemplate(
            input_variables=["instructions"],
            template=self.prompts["chain"]["manim_script_generate"]
        )

        t0 = time.perf_counter()
        plan = (manim_planer | self.flash_llm).invoke({
            "user_prompt": explain_prompt,
            "video_enhance_prompt": video_enhance_prompt or ""
        })
        t1 = time.perf_counter()
        logger.info(f"[{self.req_id}] planner LLM elapsed={t1-t0:.3f}s")

        if TRACE_LLM:
            logger.debug(f"[{self.req_id}] planner.output =\n{_clip(str(plan))}")

        t2 = time.perf_counter()
        script = (manim_script_prompt | self.pro_llm | parser).invoke({"instructions": plan})
        t3 = time.perf_counter()
        logger.info(f"[{self.req_id}] script LLM elapsed={t3-t2:.3f}s")

        if TRACE_LLM:
            logger.debug(f"[{self.req_id}] script.raw =\n{_clip(script)}")

        clean = script.replace("```python", "").replace("```", "")
        logger.debug(f"[{self.req_id}] script.cleaned_len={len(clean)}")
        return clean

    # ã‚³ãƒ¼ãƒ‰ç”ŸæˆAIã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ
    @trace
    def generate_script(self, video_instract_prompt: str) -> str:
        if TRACE_LLM:
            logger.debug(f"[{self.req_id}] generate_script.templates = "
                         f"planner:\n{_clip(self.prompts['chain']['manim_planer'])}\n"
                         f"generator:\n{_clip(self.prompts['chain']['manim_script_generate'])}")

        prompt1 = PromptTemplate(
            input_variables=["user_prompt"],
            template=self.prompts["chain"]["manim_planer"]
        )
        prompt2 = PromptTemplate(
            input_variables=["instructions"],
            template=self.prompts["chain"]["manim_script_generate"]
        )
        parser = StrOutputParser()

        t0 = time.perf_counter()
        plan = (prompt1 | self.think_llm).invoke({"user_prompt": video_instract_prompt})
        t1 = time.perf_counter()
        logger.info(f"[{self.req_id}] generate_script.plan elapsed={t1-t0:.3f}s")

        if TRACE_LLM:
            logger.debug(f"[{self.req_id}] generate_script.plan_out =\n{_clip(str(plan))}")

        t2 = time.perf_counter()
        script = (prompt2 | self.pro_llm | parser).invoke({"instructions": plan})
        t3 = time.perf_counter()
        logger.info(f"[{self.req_id}] generate_script.codegen elapsed={t3-t2:.3f}s")

        if TRACE_LLM:
            logger.debug(f"[{self.req_id}] generate_script.raw =\n{_clip(script)}")

        return script.replace("```python", "").replace("```", "")

    # --- Pyright diagnostics ç”¨ ---
    @trace
    def rag_search_related_docs_for_diagnostics(self, diagnostics: list[dict], k: int = 2) -> str:
        return self.rag_client.diagnostics_report(
            diagnostics,
            k=k,
            log_context=self.req_id,
        )

    # --- Inner Error ç”¨ ---
    @trace
    def rag_search_related_docs_for_innererror(self, inner_error: str, k: int = 3) -> str:
        return self.rag_client.runtime_error_report(
            inner_error,
            k=k,
            log_context=self.req_id,
        )

    @trace
    def fix_code_agent(self, file_name: str, concept: str, error_info, mode: str = "lint"):
        tmp_path = Path(f"tmp/{file_name}.py")
        with open(tmp_path, "r") as f:
            script = f.read()

        # --- è‡ªå‹•åˆ¤å®š ---
        auto_mode = mode
        if mode is None:
            if isinstance(error_info, dict):
                auto_mode = "lint"
            elif isinstance(error_info, str):
                auto_mode = "innererror"
            else:
                raise TypeError(f"Unsupported error_info type: {type(error_info)}")

        logger.info(f"[{self.req_id}] FixCodeAgent mode={auto_mode}")

        # --- Lintãƒ¢ãƒ¼ãƒ‰ ---
        if auto_mode == "lint":
            diagnostics = error_info.get("generalDiagnostics", [])
            related_docs = self.rag_search_related_docs_for_diagnostics(diagnostics)
            error_descriptions = "\n\n".join([
                f"[{i+1}] Rule: {d.get('rule','?')}\n"
                f"Severity: {d.get('severity')}\n"
                f"Message: {d.get('message')}"
                for i, d in enumerate(diagnostics[:10])
            ])
            error_context_title = "é™çš„è§£æï¼ˆPyrightï¼‰è¨ºæ–­çµæœ"
            logger.debug(f"[{self.req_id}] FixCodeAgent lint diag_count={len(diagnostics)}")

        # --- InnerErrorãƒ¢ãƒ¼ãƒ‰ ---
        elif auto_mode == "innererror":
            related_docs = self.rag_search_related_docs_for_innererror(error_info)
            error_descriptions = _clip(error_info, 2000)
            error_context_title = "å®Ÿè¡Œæ™‚ã‚¨ãƒ©ãƒ¼ï¼ˆManim Tracebackï¼‰"
            logger.debug(f"[{self.req_id}] FixCodeAgent innererror desc_len={len(error_descriptions)}")

        else:
            raise ValueError(f"Invalid mode: {auto_mode}")

        # Repair LLM å‘¼ã³å‡ºã—
        repair_prompt = PromptTemplate(
            input_variables=["concept_summary", "error_context_title", "error_descriptions", "related_docs", "original_script"],
            template=self.prompts["repair"]["prompt_template"]
            if "repair" in self.prompts else """
        ã‚ãªãŸã¯ãƒ—ãƒ­ã®Manimé–‹ç™ºè€…ã§ã‚ã‚Šã€Pythonã‚¨ãƒ©ãƒ¼ä¿®æ­£ã®å°‚é–€å®¶ã§ã™ã€‚
        ä»¥ä¸‹ã®æƒ…å ±ã‚’ã‚‚ã¨ã«ã‚¹ã‚¯ãƒªãƒ—ãƒˆã‚’ä¿®æ­£ã—ã¦ãã ã•ã„ã€‚

        ## ã‚³ãƒ³ã‚»ãƒ—ãƒˆæ¦‚è¦
        {concept_summary}

        ## {error_context_title}
        {error_descriptions}

        ## é–¢é€£ã™ã‚‹Manimå…¬å¼ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆï¼ˆRAGæ¤œç´¢çµæœï¼‰
        {related_docs}

        ## å…ƒã®ã‚¹ã‚¯ãƒªãƒ—ãƒˆ
        {original_script}

        ---
        ã‚¿ã‚¹ã‚¯:
        - å…¨ã¦ã®ã‚¨ãƒ©ãƒ¼ã‚’ä¿®æ­£ã—ã€Manim APIã®æ­£ã—ã„æ§‹æ–‡ãƒ»å‹ãƒ»å¼•æ•°ã«åˆã‚ã›ã‚‹
        - ä¸è¦ãªã‚³ãƒ¡ãƒ³ãƒˆã‚„èª¬æ˜ã¯æ›¸ã‹ãšã€æœ‰åŠ¹ãªPythonã‚³ãƒ¼ãƒ‰ã®ã¿å‡ºåŠ›
        - æ—¥æœ¬èªãƒ•ã‚©ãƒ³ãƒˆã‚’æ˜ç¤ºæŒ‡å®šã™ã‚‹ã‚ˆã†ã«ã—ã¦ãã ã•ã„

        å‡ºåŠ›ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ:
        ```python
        from manim import *
        class GeneratedScene(Scene):
            def construct(self):
                # ä¿®æ­£ç‰ˆã‚³ãƒ¼ãƒ‰
        """
        )
        if TRACE_LLM:
            logger.debug(f"[{self.req_id}] repair.prompt =\n{_clip(repair_prompt.template)}")

        parser = StrOutputParser()
        t0 = time.perf_counter()
        script_fixed = (repair_prompt | self.pro_llm | parser).invoke({
            "concept_summary": concept,
            "error_context_title": error_context_title,
            "error_descriptions": error_descriptions,
            "related_docs": related_docs,
            "original_script": script,
        })
        t1 = time.perf_counter()
        logger.info(f"[{self.req_id}] repair LLM elapsed={t1-t0:.3f}s out_len={len(script_fixed)}")

        if TRACE_LLM:
            logger.debug(f"[{self.req_id}] repair.output =\n{_clip(script_fixed)}")

        script_clean = script_fixed.replace("```python", "").replace("```", "")
        with open(tmp_path, "w") as f:
            f.write(script_clean)
        logger.info(f"[{self.req_id}] FixCodeAgent wrote file={tmp_path} size={len(script_clean)}")
        return script_clean

    @trace
    def parse_pyright_output_for_llm(self, pyright_json: dict) -> str:
        diagnostics = pyright_json.get("generalDiagnostics", [])
        summary = pyright_json.get("summary", {})
        logger.debug(f"[{self.req_id}] pyright: errors={summary.get('errorCount',0)} "
                     f"warnings={summary.get('warningCount',0)} files={summary.get('filesAnalyzed',0)}")

        lines = []
        for i, diag in enumerate(diagnostics, start=1):
            file = diag.get("file", "")
            rule = diag.get("rule", "")
            severity = diag.get("severity", "")
            message = diag.get("message", "").replace("\n", " ").strip()
            start_line = diag.get("range", {}).get("start", {}).get("line", "?")

            lines.append(
                f"[Error {i}]\n"
                f"file: {file}\n"
                f"rule: {rule}\n"
                f"severity: {severity}\n"
                f"line: {start_line}\n"
                f"message: {message}\n"
            )

        lines.append(
            "[Summary]\n"
            f"errorCount: {summary.get('errorCount', 0)}\n"
            f"warningCount: {summary.get('warningCount', 0)}\n"
            f"filesAnalyzed: {summary.get('filesAnalyzed', 0)}\n"
            f"timeInSec: {summary.get('timeInSec', 0)}"
        )

        return "\n".join(lines)

    @trace
    def has_no_pyright_errors(self, pyright_json: dict) -> bool:
        summary = pyright_json.get("summary", {})
        error_count = summary.get("errorCount", 0)
        ok = error_count == 0
        logger.info(f"[{self.req_id}] pyright errorCount={error_count} -> ok={ok}")
        return ok

    # ã‚¹ã‚¯ãƒªãƒ—ãƒˆç®¡ç†ã™ã‚‹ãŸã‚ã®é–¢æ•°
    @trace
    def run_script(self, video_id: str, script: str) -> str:
        if not os.path.exists("tmp"):
            os.makedirs("tmp")
        tmp_path = Path(f"tmp/{video_id}.py")
        with open(tmp_path, "w") as f:
            f.write(script)

        is_secure = is_code_safe(script)
        logger.info(f"[{self.req_id}] run_script path={tmp_path} secure={is_secure}")

        if is_secure:
            try:
                t0 = time.perf_counter()
                proc = subprocess.run(
                    ["manim", "-pql", str(tmp_path), "GeneratedScene"],
                    stdout=subprocess.PIPE,
                    stderr=subprocess.PIPE,
                    text=True, check=True
                )
                t1 = time.perf_counter()
                logger.info(f"[{self.req_id}] manim success elapsed={t1-t0:.3f}s")
                if proc.stdout:
                    logger.debug(f"[{self.req_id}] manim.stdout:\n{_clip(proc.stdout, 3000)}")
                if proc.stderr:
                    logger.debug(f"[{self.req_id}] manim.stderr:\n{_clip(proc.stderr, 3000)}")
                return "Success"
            except subprocess.CalledProcessError as e:
                logger.warning(f"[{self.req_id}] manim failed returncode={e.returncode}")
                if e.stdout:
                    logger.debug(f"[{self.req_id}] manim.stdout:\n{_clip(e.stdout, 3000)}")
                if e.stderr:
                    logger.debug(f"[{self.req_id}] manim.stderr:\n{_clip(e.stderr, 3000)}")
                return e.stderr
        else:
            logger.error(f"[{self.req_id}] run_script rejected by safety checker")
            return "bad_request"

    # å‹•ç”»ä½œæˆãƒ«ãƒ¼ãƒ—ã‚’ã‹ã‘ã‚‹
    @trace
    def generate_videos(self, video_id, content, enhance_prompt):
        logger.info(f"[{self.req_id}] generate_videos start video_id={video_id}")

        # ã‚¹ã‚¯ãƒªãƒ—ãƒˆç”Ÿæˆ
        script = self.generate_script_with_prompt(
            content,
            enhance_prompt
        )

        max_loop = 3
        loop = 0
        while loop < max_loop:
            logger.info(f"[{self.req_id}] loop={loop+1}/{max_loop}")

            if not os.path.exists("tmp"):
                os.makedirs("tmp")
            tmp_path = Path(f"tmp/{video_id}.py")
            with open(tmp_path, "w") as f:
                f.write(script)

            # Lintå®Ÿè¡Œ
            t0 = time.perf_counter()
            err = format_and_linter(tmp_path)
            t1 = time.perf_counter()
            logger.info(f"[{self.req_id}] lint elapsed={t1-t0:.3f}s")
            logger.debug(f"[{self.req_id}] lint.raw = { _clip(json.dumps(err, ensure_ascii=False), 3000) }")

            is_success = self.has_no_pyright_errors(err)

            if is_success:
                video_success = self.run_script(video_id, script)
                if video_success == "Success":
                    logger.info(f"[{self.req_id}] generate_videos SUCCESS")
                    return 'Success'
                elif video_success == "bad_request":
                    logger.error(f"[{self.req_id}] generate_videos rejected by safety -> stop")
                    return 'bad_request'
                else:
                    # å®Ÿè¡Œæ™‚ã‚¨ãƒ©ãƒ¼è§£æ
                    inner_error = parse_manim_or_python_traceback(video_success)
                    inner_error = format_error_for_llm(inner_error)
                    logger.debug(f"[{self.req_id}] inner_error.parsed =\n{_clip(inner_error, 3000)}")
                    script = self.fix_code_agent(video_id, content, inner_error, mode=None)  # è‡ªå‹•åˆ¤å®š
                    loop += 1
                    continue
            else:
                # é™çš„ã‚¨ãƒ©ãƒ¼ã‚’ã‚‚ã¨ã«ä¿®å¾©
                script = self.fix_code_agent(video_id, content, err, mode=None)  # è‡ªå‹•åˆ¤å®š
                loop += 1
                continue

        logger.error(f"[{self.req_id}] generate_videos reached max_loop -> error")
        return "error"


if __name__ == "__main__":
    service = ManimAnimationOnRAGService()
    is_success = service.generate_videos(
        video_id='sankakukannsuu',
        content="""
        # ä¸‰è§’é–¢æ•°ã®â€œå‹•ãâ€ã‚’å˜ä½å††ã§ä½“æ„Ÿã—ã‚ˆã† --- ## 0. ä»Šæ—¥ã®ã‚´ãƒ¼ãƒ« - ã€ŒsinÎ¸, cosÎ¸ã®â€œãšã‚‰ã—â€ã‚„ç¬¦å·ã«ã¤ã„ã¦ã€ãªãœã‹ã‚’å‹•ãã§å®Ÿæ„Ÿã—ã‚ˆã†ã€ - çµè«–ï¼š\\(\\cos\\theta = \\sin(\\theta+\\frac{\\pi}{2})\\)ã€\\(\\sin\\theta = -\\cos(\\theta+\\frac{\\pi}{2})\\)ãŒå˜ä½å††ã§ä½“æ„Ÿã§ãã‚‹ã“ã¨ã‚’ç›®æŒ‡ã™ --- ## 1. å˜ä½å††ã§ä¸‰è§’é–¢æ•°ã‚¹ã‚¿ãƒ¼ãƒˆï¼ ã¾ãšåŠå¾„1ï¼ˆåŸç‚¹ä¸­å¿ƒï¼‰ã®å††**å˜ä½å††**ã‚’ç”¨æ„ã—ã‚ˆã†ã€‚ - xè»¸ã®æ­£ã®æ–¹å‘ï¼ˆå³å‘ãï¼‰ã‚’0Â°ã€ãã“ã‹ã‚‰åæ™‚è¨ˆå›ã‚Šã«è§’åº¦\\(\\theta\\)ã‚’ã¨ã‚‹ã—ãŸãŒã£ã¦ã€  $$ \\cos^2 \\theta + \\sin^2 \\theta = 1 $$ã¨ã„ã† **ä¸‰è§’é–¢æ•°ã®åŸºæœ¬çš„ãªé–¢ä¿‚å¼** ãŒå¾—ã‚‰ã‚Œã¾ã™
        """,
        enhance_prompt=""
    )
    print(is_success)
