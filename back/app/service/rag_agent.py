import os
import subprocess
from pathlib import Path
from dotenv import load_dotenv
import tomllib
from langchain_google_genai import ChatGoogleGenerativeAI
from langchain.prompts import PromptTemplate
from langchain.schema.runnable import RunnableSequence
from langchain_core.output_parsers import StrOutputParser

import re
from langchain_huggingface import HuggingFaceEmbeddings
from langchain_chroma import Chroma
from pathlib import Path

from app.tools.lint import format_and_linter
from app.tools.manim_lint import parse_manim_or_python_traceback,format_error_for_llm
from app.tools.secure import is_code_safe


load_dotenv()

class ManimAnimationOnRAGService:
    def __init__(self):
        base_dir = Path(__file__).resolve().parent
        prompts_path = base_dir / "prompts.toml"
        prompts_path = str(prompts_path)
        with open(prompts_path, 'rb') as f:
            self.prompts = tomllib.load(f)
        self.think_llm = self._load_llm("gemini-2.5-flash")
        self.pro_llm   = self._load_llm("gemini-2.5-pro")
        self.flash_llm = self._load_llm("gemini-2.5-flash")
        self.lite_llm  = self._load_llm("gemini-2.5-flash-lite")
    def _load_llm(self, model_type: str):
        return ChatGoogleGenerativeAI(model=model_type, google_api_key=os.getenv('GEMINI_API_KEY'))
    
    # çŸ¥è­˜ã®æ§‹é€ åŒ–èª¬æ˜
    def explain_concept(self,input_text: str) -> str:
        prompt = PromptTemplate(
            input_variables=["input_text"],
            template=self.prompts["explain"]["prompt"]
        )
        parser = StrOutputParser()
        chain = RunnableSequence(
            first=prompt | self.flash_llm,
            last=parser
        )
        output = chain.invoke({"input_text": input_text})
        return output
    
    # ã‚¹ã‚¯ãƒªãƒ—ãƒˆã‚’ä½œæˆã™ã‚‹æœ€æ–°prompt
    def generate_script_with_prompt(self,explain_prompt,video_enhance_prompt):
        """
        å‹•ç”»ã®ã‚¹ã‚¯ãƒªãƒ—ãƒˆã‚’ç”Ÿæˆã™ã‚‹é–¢æ•°
        input:
            explain_prompt : çŸ¥è­˜ã®æ§‹é€ åŒ–èª¬æ˜
            video_enhance_prompt : ãƒ“ãƒ‡ã‚ªã®å‹•ç”»ã‚’æŒ‡å°ã™ã‚‹ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ 
        output:
            script: å‹•ç”»ã‚¹ã‚¯ãƒªãƒ—ãƒˆ
        """
        manim_planer = PromptTemplate(
            input_variables=['user_prompt'],
            optional_variables= ['video_enhance_prompt'],
            template=self.prompts['chain']['manim_planer_with_instruct']
        )
        parser = StrOutputParser() 
        
        manim_script_prompt = PromptTemplate(
            input_variables=["instructions"],
            template=self.prompts["chain"]["manim_script_generate"]
        )
        
        chain = RunnableSequence(
            first= manim_planer | self.flash_llm,
            last= manim_script_prompt | self.pro_llm | parser
        )
        
        output = chain.invoke(
            {
                "user_prompt":explain_prompt,
                "video_enhance_prompt":video_enhance_prompt
            }
        )
        return output.replace("```python", "").replace("```", "")
    
    # ã‚³ãƒ¼ãƒ‰ç”ŸæˆAIã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ
    def generate_script(self, video_instract_prompt: str) -> str:
        prompt1 = PromptTemplate(
            input_variables=["user_prompt"],
            template=self.prompts["chain"]["manim_planer"]
        )
        prompt2 = PromptTemplate(
            input_variables=["instructions"],
            template=self.prompts["chain"]["manim_script_generate"]
        )
        parser = StrOutputParser()
        chain = RunnableSequence(
            first=prompt1 | self.think_llm,
            last=prompt2 | self.pro_llm | parser
        )
        output = chain.invoke({"user_prompt" : video_instract_prompt})
        return output.replace("```python", "").replace("```", "")
    
    def _load_rag_db(self):
        """Manimå…¬å¼ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆRAGãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚’ãƒ­ãƒ¼ãƒ‰"""
        db_dir = Path(__file__).resolve().parent.parent / "tools" / "embeding_data" / "manim_chroma_db"
        embedding_function = HuggingFaceEmbeddings(model_name="jinaai/jina-code-embeddings-1.5b")
        return Chroma(
            collection_name="manim_docs",
            persist_directory=str(db_dir),
            embedding_function=embedding_function,
        )

    def rag_search_related_docs(self, diagnostics: list[dict], k: int = 2) -> str:
        """
        å„Pyright diagnosticã«å¯¾ã—ã¦RAGæ¤œç´¢ã‚’è¡Œã„ã€
        ruleã”ã¨ã«ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚’ã¾ã¨ã‚ã¦è¿”ã™ã€‚
        """
        db = self._load_rag_db()
        seen_urls = set()
        rule_to_docs = {}

        for diag in diagnostics:
            message = diag.get("message", "")
            rule = diag.get("rule", "unknown")
            # Manim APIåãªã©ã‚’å„ªå…ˆçš„ã«æ¤œç´¢ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã«
            manim_refs = re.findall(r"manim[\.\w]+", message)
            query = " ".join(manim_refs) if manim_refs else message[:160]

            results = db.similarity_search(query, k=k)
            docs = []
            for r in results:
                url = r.metadata.get("source_url", "")
                if url not in seen_urls:
                    seen_urls.add(url)
                    docs.append(
                        f"- {r.metadata.get('full_name', '')}\n"
                        f"{r.page_content[:300]}...\n"
                        f"URL: {url}\n"
                    )

            if docs:
                if rule not in rule_to_docs:
                    rule_to_docs[rule] = []
                rule_to_docs[rule].extend(docs)

        if not rule_to_docs:
            return "No related documentation found."

        # å„ruleã”ã¨ã«ä¸Šä½2ä»¶ãšã¤ã¾ã¨ã‚ã‚‹
        doc_sections = []
        for rule, docs in rule_to_docs.items():
            section = f"### Rule: {rule}\n" + "\n".join(docs[:2])
            doc_sections.append(section)

        return "\n\n".join(doc_sections[:5])
    
    
    def fix_code_agent(self, file_name: str, concept: str, pyright_json: dict):
        """
        RAGã‚’çµ±åˆã—ãŸã‚³ãƒ¼ãƒ‰ä¿®æ­£AIã€‚
        - å„ã‚¨ãƒ©ãƒ¼ï¼ˆdiagnosticï¼‰ã”ã¨ã«Manimãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚’å‚ç…§ã—ã€
        æ§‹æ–‡ã¨å‹ã‚’æ„è­˜ã—ãŸä¿®æ­£ç‰ˆã‚’å‡ºåŠ›ã™ã‚‹ã€‚
        """
        tmp_path = Path(f"tmp/{file_name}.py")
        with open(tmp_path, "r") as f:
            script = f.read()

        diagnostics = pyright_json.get("generalDiagnostics", [])
        summary = pyright_json.get("summary", {})
        if not diagnostics:
            print("âš ï¸ No diagnostics found for fix_code_agent().")
            return script

        # ğŸ” è¤‡æ•°ã‚¨ãƒ©ãƒ¼ã«å¯¾ã—ã¦RAGæ¤œç´¢
        related_docs = self.rag_search_related_docs(diagnostics)
        print("RAGè§£æå®Œäº†!")

        # å„ã‚¨ãƒ©ãƒ¼ã‚’äººé–“ãŒç†è§£ã—ã‚„ã™ã„ã‚ˆã†ã«æ•´å½¢
        error_descriptions = "\n\n".join([
            f"[{i+1}] Rule: {d.get('rule','?')}\n"
            f"Severity: {d.get('severity')}\n"
            f"Message: {d.get('message')}"
            for i, d in enumerate(diagnostics[:10])
        ])

        repair_prompt = PromptTemplate(
            input_variables=["concept_summary", "error_descriptions", "related_docs", "original_script"],
            template="""
        ã‚ãªãŸã¯ãƒ—ãƒ­ã® Manim é–‹ç™ºè€…ã‹ã¤Python Linterã®å°‚é–€å®¶ã§ã™ã€‚

        ä»¥ä¸‹ã®æƒ…å ±ã‚’å‚è€ƒã«ã€ã‚¹ã‚¯ãƒªãƒ—ãƒˆã®ã™ã¹ã¦ã®ã‚¨ãƒ©ãƒ¼ã‚’ä¿®æ­£ã—ã¦ãã ã•ã„ã€‚

        ## ã‚³ãƒ³ã‚»ãƒ—ãƒˆæ¦‚è¦
        {concept_summary}

        ## é™çš„è§£æã‚¨ãƒ©ãƒ¼ä¸€è¦§
        {error_descriptions}

        ## å‚è€ƒãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆï¼ˆManim RAGæ¤œç´¢çµæœï¼‰
        {related_docs}

        ## å…ƒã®ã‚¹ã‚¯ãƒªãƒ—ãƒˆ
        {original_script}

        ---
        ã‚¿ã‚¹ã‚¯:
        - å…¨ã¦ã®ã‚¨ãƒ©ãƒ¼ã‚’ä¿®æ­£ã—ã€Manim APIã®æ­£ã—ã„æ§‹æ–‡ã«åˆã‚ã›ã‚‹
        - ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã§èª¬æ˜ã•ã‚ŒãŸæ­£ã—ã„ã‚¯ãƒ©ã‚¹ãƒ»é–¢æ•°ãƒ»å¼•æ•°ã‚’åˆ©ç”¨ã™ã‚‹
        - ã‚³ãƒ¡ãƒ³ãƒˆã‚„èª¬æ˜ã¯æ›¸ã‹ãšã€å®Ÿè¡Œå¯èƒ½ãªPythonã‚³ãƒ¼ãƒ‰ã®ã¿ã‚’å‡ºåŠ›ã™ã‚‹

        å‡ºåŠ›ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ:
        ```python
        from manim import *
        class GeneratedScene(Scene):
            def construct(self):
                # ä¿®æ­£ç‰ˆã‚³ãƒ¼ãƒ‰
        ```
        """
        )

        parser = StrOutputParser()
        chain = repair_prompt | self.pro_llm | parser  # Gemini-proã‚’åˆ©ç”¨ï¼ˆæ§‹æ–‡ç”ŸæˆãŒå¼·ã„ï¼‰

        script = chain.invoke(
            {
                "concept_summary": concept,
                "error_descriptions": error_descriptions,
                "related_docs": related_docs,
                "original_script": script,
            }
        )

        script_clean = script.replace("```python", "").replace("```", "")
        with open(tmp_path, "w") as f:
            f.write(script_clean)
        return script_clean

    def parse_pyright_output_for_llm(self,pyright_json: dict) -> str:
        """Convert Pyright JSON diagnostics into structured plain text for LLM input."""
        diagnostics = pyright_json.get("generalDiagnostics", [])
        summary = pyright_json.get("summary", {})

        lines = []
        for i, diag in enumerate(diagnostics, start=1):
            file = diag.get("file", "")
            rule = diag.get("rule", "")
            severity = diag.get("severity", "")
            message = diag.get("message", "").replace("\n", " ").strip()
            start_line = diag.get("range", {}).get("start", {}).get("line", "?")

            lines.append(
                f"[Error {i}]\n"
                f"file: {file}\n"
                f"rule: {rule}\n"
                f"severity: {severity}\n"
                f"line: {start_line}\n"
                f"message: {message}\n"
            )

        lines.append(
            "[Summary]\n"
            f"errorCount: {summary.get('errorCount', 0)}\n"
            f"warningCount: {summary.get('warningCount', 0)}\n"
            f"filesAnalyzed: {summary.get('filesAnalyzed', 0)}\n"
            f"timeInSec: {summary.get('timeInSec', 0)}"
        )

        return "\n".join(lines)

    def has_no_pyright_errors(self,pyright_json: dict) -> bool:
        """
        Return True if there are no Pyright errors (errorCount == 0), else False.

        Args:
            pyright_json (dict): Parsed Pyright JSON output.

        Returns:
            bool: True if no errors, False otherwise.
        """
        summary = pyright_json.get("summary", {})
        error_count = summary.get("errorCount", 0)
        return error_count == 0
    
     # ã‚¹ã‚¯ãƒªãƒ—ãƒˆç®¡ç†ã™ã‚‹ãŸã‚ã®é–¢æ•°
    def run_script(self, video_id: str, script: str) -> str:
        if not os.path.exists("tmp"):
            os.makedirs("tmp")
        tmp_path = Path(f"tmp/{video_id}.py")
        with open(tmp_path, "w") as f:
            f.write(script)
        is_secure=is_code_safe(script)
        if is_secure:
            try:
                subprocess.run(
                    ["manim", "-pql", str(tmp_path), "GeneratedScene"],
                    stdout=subprocess.PIPE,
                    stderr=subprocess.PIPE,
                    text=True, check=True
                )
                return "Success"
            except subprocess.CalledProcessError as e:
                return e.stderr
        else:
            return "bad_request"
    
    # å‹•ç”»ä½œæˆãƒ«ãƒ¼ãƒ—ã‚’ã‹ã‘ã‚‹
    def generate_videos(self,video_id,content,enhance_prompt):
        # ã‚¹ã‚¯ãƒªãƒ—ãƒˆç”Ÿæˆ
        script = self.generate_script_with_prompt(
            content,
            enhance_prompt
        )
        max_loop = 3
        loop = 0
        while loop < max_loop:
             # ã‚¹ã‚¯ãƒªãƒ—ãƒˆã‚’ç®¡ç†ã™ã‚‹
            if not os.path.exists("tmp"):
                os.makedirs("tmp")
            tmp_path = Path(f"tmp/{video_id}.py")
            with open(tmp_path, "w") as f:
                f.write(script)
            # tmp_pathã«å¯¾ã—ã¦ã€format_and_linterã‚’å›ã™
            err =  format_and_linter(tmp_path)
            print(err)
            err_paser_output_llm=self.parse_pyright_output_for_llm(err)
            is_success = self.has_no_pyright_errors(err)
            if is_success:
                video_success = self.run_script(video_id,script)
                if video_success=="Success":
                    return 'Success'
                elif video_success=="bad_request":
                    return 'bad_request'
                else:
                    inner_error = parse_manim_or_python_traceback(video_success)
                    inner_error = format_error_for_llm(inner_error)
                    script = self.fix_code_agent(video_id,content,inner_error)
                    loop += 1
                    continue
            else:
                script = self.fix_code_agent(video_id,content,err_paser_output_llm)
                loop += 1
                continue
        return "error"
    
if __name__ == "__main__":
    service = ManimAnimationOnRAGService()
    is_success = service.generate_videos(
        video_id='sankakukannsuu',
        content="""
        # ä¸‰è§’é–¢æ•°ã®â€œå‹•ãâ€ã‚’å˜ä½å††ã§ä½“æ„Ÿã—ã‚ˆã† --- ## 0. ä»Šæ—¥ã®ã‚´ãƒ¼ãƒ« - ã€ŒsinÎ¸, cosÎ¸ã®â€œãšã‚‰ã—â€ã‚„ç¬¦å·ã«ã¤ã„ã¦ã€ãªãœã‹ã‚’å‹•ãã§å®Ÿæ„Ÿã—ã‚ˆã†ã€ - çµè«–ï¼š\(\cos\theta = \sin(\theta+\frac{\pi}{2})\)ã€\(\sin\theta = -\cos(\theta+\frac{\pi}{2})\)ãŒå˜ä½å††ã§ä½“æ„Ÿã§ãã‚‹ã“ã¨ã‚’ç›®æŒ‡ã™ --- ## 1. å˜ä½å††ã§ä¸‰è§’é–¢æ•°ã‚¹ã‚¿ãƒ¼ãƒˆï¼ ã¾ãšåŠå¾„1ï¼ˆåŸç‚¹ä¸­å¿ƒï¼‰ã®å††ï¼**å˜ä½å††**ã‚’ç”¨æ„ã—ã‚ˆã†ã€‚ - xè»¸ã®æ­£ã®æ–¹å‘ï¼ˆå³å‘ãï¼‰ã‚’0Â°ã€ãã“ã‹ã‚‰åæ™‚è¨ˆå›ã‚Šã«è§’åº¦\(\theta\)ã‚’ã¨ã‚‹ã—ãŸãŒã£ã¦ã€  $$ \cos^2 \theta + \sin^2 \theta = 1 $$ã¨ã„ã† **ä¸‰è§’é–¢æ•°ã®åŸºæœ¬çš„ãªé–¢ä¿‚å¼** ãŒå¾—ã‚‰ã‚Œã¾ã™
        """,
        enhance_prompt=""
    )
    print(is_success)